{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application du *transfer learning* à la problématique de classification des images des produits\n",
    "\n",
    "* Commencer avec VGG\n",
    "* Trouver un exemple d'application de la reconnaissance à une collection d'images.\n",
    "* Appliquer sur les lots de 8, puis 100, puis les 1050 : ajouter la mesure du temps.\n",
    "* Ajouter une couche de classif : logistique, kmeans, etc : essayer plusieurs alternatives.\n",
    "* Ajouter la mesure des performances : si elle sont bluffantes, ce sera encourageant à terminer rapidement le projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annexe. [**Transfer Learning in Keras with Computer Vision Models**](https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/)\n",
    "\n",
    "Deep convolutional neural network models may take days or even weeks to train on very large datasets.\n",
    "\n",
    "A way to short-cut this process is to re-use the model weights from pre-trained models that were developed for standard computer vision benchmark datasets, such as the ImageNet image recognition tasks. Top performing models can be downloaded and used directly, or integrated into a new model for your own computer vision problems.\n",
    "\n",
    "In this post, you will discover how to use [**transfer learning**](https://machinelearningmastery.com/transfer-learning-for-deep-learning/) when developing convolutional neural networks for computer vision applications.\n",
    "\n",
    "After reading this post, you will know:\n",
    "* Transfer learning involves using models trained on one problem as a starting point on a related problem.\n",
    "* Transfer learning is flexible, allowing the use of pre-trained models directly, as feature extraction preprocessing, and integrated into entirely new models.\n",
    "* Keras provides convenient access to many top performing models on the ImageNet image recognition tasks such as VGG, Inception, and ResNet.\n",
    "\n",
    "Let’s get started."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This tutorial is divided into five parts; they are:\n",
    "1. What Is Transfer Learning?\n",
    "2. Transfer Learning for Image Recognition\n",
    "3. How to Use Pre-Trained Models\n",
    "4. Models for Transfer Learning\n",
    "5. Examples of Using Pre-Trained Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Is Transfer Learning?\n",
    "\n",
    "Transfer learning generally refers to a process where a model trained on one problem is used in some way on a second related problem.\n",
    "\n",
    "In deep learning, transfer learning is a technique whereby a neural network model is first trained on a problem similar to the problem that is being solved. One or more layers from the trained model are then used in a new model trained on the problem of interest.\n",
    "\n",
    "This is typically understood in a supervised learning context, where the input is the same but the target may be of a different nature. For example, we may learn about one set of visual categories, such as cats and dogs, in the first setting, then learn about a different set of visual categories, such as ants and wasps, in the second setting.\n",
    "\n",
    "Transfer learning has the benefit of decreasing the training time for a neural network model and can result in lower generalization error.\n",
    "\n",
    "The weights in re-used layers may be used as the starting point for the training process and adapted in response to the new problem. This usage treats transfer learning as a type of weight initialization scheme. This may be useful when the first related problem has a lot more labeled data than the problem of interest and the similarity in the structure of the problem may be useful in both contexts.\n",
    "\n",
    "The objective is to take advantage of data from the first setting to extract information that may be useful when learning or even when directly making predictions in the second setting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning for Image Recognition\n",
    "\n",
    "A range of high-performing models have been developed for image classification and demonstrated on the annual ImageNet Large Scale Visual Recognition Challenge, or ILSVRC.\n",
    "\n",
    "This challenge, often referred to simply as ImageNet, given the source of the image used in the competition, has resulted in a number of innovations in the architecture and training of convolutional neural networks. In addition, many of the models used in the competitions have been released under a permissive license.\n",
    "\n",
    "These models can be used as the basis for transfer learning in computer vision applications.\n",
    "\n",
    "This is desirable for a number of reasons, not least:\n",
    "* **Useful Learned Features**: The models have learned how to detect generic features from photographs, given that they were trained on more than 1,000,000 images for 1,000 categories.\n",
    "* **State-of-the-Art Performance**: The models achieved state of the art performance and remain effective on the specific image recognition task for which they were developed.\n",
    "* **Easily Accessible**: The model weights are provided as free downloadable files and many libraries provide convenient APIs to download and use the models directly.\n",
    "\n",
    "The model weights can be downloaded and used in the same model architecture using a range of different deep learning libraries, including Keras."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Use Pre-Trained Models\n",
    "\n",
    "The use of a pre-trained model is limited only by your creativity.\n",
    "\n",
    "For example, a model may be downloaded and used as-is, such as embedded into an application and used to classify new photographs.\n",
    "\n",
    "Alternately, models may be downloaded and use as feature extraction models. Here, the output of the model from a layer prior to the output layer of the model is used as input to a new classifier model.\n",
    "\n",
    "Recall that convolutional layers closer to the input layer of the model learn low-level features such as lines, that layers in the middle of the layer learn complex abstract features that combine the lower level features extracted from the input, and layers closer to the output interpret the extracted features in the context of a classification task.\n",
    "\n",
    "Armed with this understanding, a level of detail for feature extraction from an existing pre-trained model can be chosen. For example, if a new task is quite different from classifying objects in photographs (e.g. different to ImageNet), then perhaps the output of the pre-trained model after the few layers would be appropriate. If a new task is quite similar to the task of classifying objects in photographs, then perhaps the output from layers much deeper in the model can be used, or even the output of the fully connected layer prior to the output layer can be used.\n",
    "\n",
    "The pre-trained model can be used as a separate feature extraction program, in which case input can be pre-processed by the model or portion of the model to a given an output (e.g. vector of numbers) for each input image, that can then use as input when training a new model.\n",
    "\n",
    "Alternately, the pre-trained model or desired portion of the model can be integrated directly into a new neural network model. In this usage, the weights of the pre-trained can be frozen so that they are not updated as the new model is trained. Alternately, the weights may be updated during the training of the new model, perhaps with a lower learning rate, allowing the pre-trained model to act like a weight initialization scheme when training the new model.\n",
    "\n",
    "We can summarize some of these usage patterns as follows:\n",
    "* **Classifier**: The pre-trained model is used directly to classify new images.\n",
    "* **Standalone Feature Extractor**: The pre-trained model, or some portion of the model, is used to pre-process images and extract relevant features.\n",
    "* **Integrated Feature Extractor**: The pre-trained model, or some portion of the model, is integrated into a new model, but layers of the pre-trained model are frozen during training.\n",
    "* **Weight Initialization**: The pre-trained model, or some portion of the model, is integrated into a new model, and the layers of the pre-trained model are trained in concert with the new model.\n",
    "\n",
    "Each approach can be effective and save significant time in developing and training a deep convolutional neural network model.\n",
    "\n",
    "It may not be clear as to which usage of the pre-trained model may yield the best results on your new computer vision task, therefore some experimentation may be required."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models for Transfer Learning\n",
    "\n",
    "There are perhaps a dozen or more top-performing models for image recognition that can be downloaded and used as the basis for image recognition and related computer vision tasks.\n",
    "\n",
    "Perhaps three of the more popular models are as follows:\n",
    "* VGG (e.g. VGG16 or VGG19).\n",
    "* GoogLeNet (e.g. InceptionV3).\n",
    "* Residual Network (e.g. ResNet50).\n",
    "\n",
    "These models are both widely used for transfer learning both because of their performance, but also because they were examples that introduced specific architectural innovations, namely consistent and repeating structures (VGG), inception modules (GoogLeNet), and residual modules (ResNet).\n",
    "\n",
    "Keras provides access to a number of top-performing pre-trained models that were developed for image recognition tasks.\n",
    "\n",
    "They are available via the [**Applications API**](https://keras.io/api/applications/), and include functions to load a model with or without the pre-trained weights, and prepare data in a way that a given model may expect (e.g. scaling of size and pixel values).\n",
    "\n",
    "The first time a pre-trained model is loaded, Keras will download the required model weights, which may take some time given the speed of your internet connection. Weights are stored in the .keras/models/ directory under your home directory and will be loaded from this location the next time that they are used.\n",
    "\n",
    "When loading a given model, the `include_top` argument can be set to `False`, in which case the fully-connected output layers of the model used to make predictions is not loaded, allowing a new output layer to be added and trained. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "# load model without output layer\n",
    "model = VGG16(include_top=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, when the `include_top` argument is `False`, the `input_tensor` argument must be specified, allowing the expected fixed-sized input of the model to be changed. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input\n",
    "# load model and specify a new input shape for images\n",
    "new_input = Input(shape=(640, 480, 3))\n",
    "model = VGG16(include_top=False, input_tensor=new_input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model without a top will output activations from the last convolutional or pooling layer directly. One approach to summarizing these activations for thier use in a classifier or as a feature vector representation of input is to add a global pooling layer, such as a max global pooling or average global pooling. The result is a vector that can be used as a feature descriptor for an input. Keras provides this capability directly via the `pooling` argument that can be set to `avg` or `max`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and specify a new input shape for images and avg pooling output\n",
    "new_input = Input(shape=(640, 480, 3))\n",
    "model = VGG16(include_top=False, input_tensor=new_input, pooling='avg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images can be prepared for a given model using the `preprocess_input()` function; e.g., pixel scaling is performed in a way that was performed to images in the training dataset when the model was developed. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 files belonging to 1 classes.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'BatchDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../tmp/preproc_images/sample_100/rgb/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m images \u001b[39m=\u001b[39m image_dataset_from_directory(path, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m----> 6\u001b[0m prepared_images \u001b[39m=\u001b[39m preprocess_input(images)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\applications\\vgg16.py:257\u001b[0m, in \u001b[0;36mpreprocess_input\u001b[1;34m(x, data_format)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mkeras.applications.vgg16.preprocess_input\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    256\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_input\u001b[39m(x, data_format\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 257\u001b[0m     \u001b[39mreturn\u001b[39;00m imagenet_utils\u001b[39m.\u001b[39;49mpreprocess_input(\n\u001b[0;32m    258\u001b[0m         x, data_format\u001b[39m=\u001b[39;49mdata_format, mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcaffe\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m    259\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\applications\\imagenet_utils.py:123\u001b[0m, in \u001b[0;36mpreprocess_input\u001b[1;34m(x, data_format, mode)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m _preprocess_numpy_input(x, data_format\u001b[39m=\u001b[39mdata_format, mode\u001b[39m=\u001b[39mmode)\n\u001b[0;32m    122\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m _preprocess_symbolic_input(x, data_format\u001b[39m=\u001b[39;49mdata_format, mode\u001b[39m=\u001b[39;49mmode)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\applications\\imagenet_utils.py:287\u001b[0m, in \u001b[0;36m_preprocess_symbolic_input\u001b[1;34m(x, data_format, mode)\u001b[0m\n\u001b[0;32m    284\u001b[0m         x \u001b[39m=\u001b[39m x[:, ::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]\n\u001b[0;32m    285\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    286\u001b[0m     \u001b[39m# 'RGB'->'BGR'\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m     x \u001b[39m=\u001b[39m x[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m, ::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\n\u001b[0;32m    288\u001b[0m mean \u001b[39m=\u001b[39m [\u001b[39m103.939\u001b[39m, \u001b[39m116.779\u001b[39m, \u001b[39m123.68\u001b[39m]\n\u001b[0;32m    289\u001b[0m std \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'BatchDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# prepare an image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.utils import image_dataset_from_directory\n",
    "path = \"../tmp/preproc_images/sample_100/rgb/\"\n",
    "images = image_dataset_from_directory(path, labels=None)  # TODO A revoir\n",
    "prepared_images = preprocess_input(images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you may wish to use a model architecture on your dataset, but not use the pre-trained weights, and instead initialize the model with random weights and train the model from scratch.\n",
    "\n",
    "This can be achieved by setting the `weights` argument to None instead of the default `imagenet`. Additionally, the `classes` argument can be set to define the number of classes in your dataset, which will then be configured for you in the output layer of the model. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# define a new model with random weights and 10 classes\u001b[39;00m\n\u001b[0;32m      2\u001b[0m new_input \u001b[39m=\u001b[39m Input(shape\u001b[39m=\u001b[39m(\u001b[39m640\u001b[39m, \u001b[39m480\u001b[39m, \u001b[39m3\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m model \u001b[39m=\u001b[39m VGG16(weights\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, input_tensor\u001b[39m=\u001b[39;49mnew_input, classes\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\applications\\vgg16.py:210\u001b[0m, in \u001b[0;36mVGG16\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39mif\u001b[39;00m include_top:\n\u001b[0;32m    208\u001b[0m     \u001b[39m# Classification block\u001b[39;00m\n\u001b[0;32m    209\u001b[0m     x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mFlatten(name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mflatten\u001b[39m\u001b[39m\"\u001b[39m)(x)\n\u001b[1;32m--> 210\u001b[0m     x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39;49mDense(\u001b[39m4096\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m\"\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfc1\u001b[39;49m\u001b[39m\"\u001b[39;49m)(x)\n\u001b[0;32m    211\u001b[0m     x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mDense(\u001b[39m4096\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfc2\u001b[39m\u001b[39m\"\u001b[39m)(x)\n\u001b[0;32m    213\u001b[0m     imagenet_utils\u001b[39m.\u001b[39mvalidate_activation(classifier_activation, weights)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\base_layer.py:1045\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# Functional Model construction mode is invoked when `Layer`s are called\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m# on symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39mif\u001b[39;00m _in_functional_construction_mode(\n\u001b[0;32m   1043\u001b[0m     \u001b[39mself\u001b[39m, inputs, args, kwargs, input_list\n\u001b[0;32m   1044\u001b[0m ):\n\u001b[1;32m-> 1045\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_functional_construction_call(\n\u001b[0;32m   1046\u001b[0m         inputs, args, kwargs, input_list\n\u001b[0;32m   1047\u001b[0m     )\n\u001b[0;32m   1049\u001b[0m \u001b[39m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[0;32m   1050\u001b[0m call_context \u001b[39m=\u001b[39m base_layer_utils\u001b[39m.\u001b[39mcall_context()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\base_layer.py:2535\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   2528\u001b[0m         training_arg_passed_by_framework \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   2530\u001b[0m \u001b[39mwith\u001b[39;00m call_context\u001b[39m.\u001b[39menter(\n\u001b[0;32m   2531\u001b[0m     layer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, inputs\u001b[39m=\u001b[39minputs, build_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39mtraining_value\n\u001b[0;32m   2532\u001b[0m ):\n\u001b[0;32m   2533\u001b[0m     \u001b[39m# Check input assumptions set after layer building, e.g. input\u001b[39;00m\n\u001b[0;32m   2534\u001b[0m     \u001b[39m# shape.\u001b[39;00m\n\u001b[1;32m-> 2535\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_keras_tensor_symbolic_call(\n\u001b[0;32m   2536\u001b[0m         inputs, input_masks, args, kwargs\n\u001b[0;32m   2537\u001b[0m     )\n\u001b[0;32m   2539\u001b[0m     \u001b[39mif\u001b[39;00m outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2540\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2541\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mA layer\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms `call` method should return a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2542\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTensor or a list of Tensors, not None \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2543\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m(layer: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2544\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\base_layer.py:2382\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m   2378\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   2379\u001b[0m         keras_tensor\u001b[39m.\u001b[39mKerasTensor, output_signature\n\u001b[0;32m   2380\u001b[0m     )\n\u001b[0;32m   2381\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2382\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infer_output_signature(\n\u001b[0;32m   2383\u001b[0m         inputs, args, kwargs, input_masks\n\u001b[0;32m   2384\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\base_layer.py:2439\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m   2431\u001b[0m \u001b[39mwith\u001b[39;00m backend\u001b[39m.\u001b[39mname_scope(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name_scope()):\n\u001b[0;32m   2432\u001b[0m     \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   2433\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   2434\u001b[0m     ):\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2437\u001b[0m         \u001b[39m# TODO(kaftan): do we maybe_build here, or have we already\u001b[39;00m\n\u001b[0;32m   2438\u001b[0m         \u001b[39m# done it?\u001b[39;00m\n\u001b[1;32m-> 2439\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_build(inputs)\n\u001b[0;32m   2440\u001b[0m         inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[0;32m   2441\u001b[0m         outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\base_layer.py:2986\u001b[0m, in \u001b[0;36mLayer._maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2981\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild, \u001b[39m\"\u001b[39m\u001b[39m_is_default\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m   2982\u001b[0m     \u001b[39m# Any setup work performed only once should happen in an\u001b[39;00m\n\u001b[0;32m   2983\u001b[0m     \u001b[39m# `init_scope` to avoid creating symbolic Tensors that will\u001b[39;00m\n\u001b[0;32m   2984\u001b[0m     \u001b[39m# later pollute any eager operations.\u001b[39;00m\n\u001b[0;32m   2985\u001b[0m     \u001b[39mwith\u001b[39;00m tf_utils\u001b[39m.\u001b[39mmaybe_init_scope(\u001b[39mself\u001b[39m):\n\u001b[1;32m-> 2986\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild(input_shapes)\n\u001b[0;32m   2987\u001b[0m \u001b[39m# We must set also ensure that the layer is marked as built, and the\u001b[39;00m\n\u001b[0;32m   2988\u001b[0m \u001b[39m# build shape is stored since user defined build functions may not\u001b[39;00m\n\u001b[0;32m   2989\u001b[0m \u001b[39m# be calling `super.build()`\u001b[39;00m\n\u001b[0;32m   2990\u001b[0m Layer\u001b[39m.\u001b[39mbuild(\u001b[39mself\u001b[39m, input_shapes)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\layers\\core\\dense.py:154\u001b[0m, in \u001b[0;36mDense.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe last dimension of the inputs to a Dense layer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    150\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mshould be defined. Found None. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    151\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFull input shape received: \u001b[39m\u001b[39m{\u001b[39;00minput_shape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    152\u001b[0m     )\n\u001b[0;32m    153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_spec \u001b[39m=\u001b[39m InputSpec(min_ndim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, axes\u001b[39m=\u001b[39m{\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m: last_dim})\n\u001b[1;32m--> 154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_weight(\n\u001b[0;32m    155\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mkernel\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    156\u001b[0m     shape\u001b[39m=\u001b[39;49m[last_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munits],\n\u001b[0;32m    157\u001b[0m     initializer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_initializer,\n\u001b[0;32m    158\u001b[0m     regularizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_regularizer,\n\u001b[0;32m    159\u001b[0m     constraint\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_constraint,\n\u001b[0;32m    160\u001b[0m     dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype,\n\u001b[0;32m    161\u001b[0m     trainable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    162\u001b[0m )\n\u001b[0;32m    163\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias:\n\u001b[0;32m    164\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_weight(\n\u001b[0;32m    165\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    166\u001b[0m         shape\u001b[39m=\u001b[39m[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    173\u001b[0m         trainable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    174\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\base_layer.py:711\u001b[0m, in \u001b[0;36mLayer.add_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[39mif\u001b[39;00m layout:\n\u001b[0;32m    709\u001b[0m     getter \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(getter, layout\u001b[39m=\u001b[39mlayout)\n\u001b[1;32m--> 711\u001b[0m variable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_variable_with_custom_getter(\n\u001b[0;32m    712\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    713\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[0;32m    714\u001b[0m     \u001b[39m# TODO(allenl): a `make_variable` equivalent should be added as a\u001b[39;49;00m\n\u001b[0;32m    715\u001b[0m     \u001b[39m# `Trackable` method.\u001b[39;49;00m\n\u001b[0;32m    716\u001b[0m     getter\u001b[39m=\u001b[39;49mgetter,\n\u001b[0;32m    717\u001b[0m     \u001b[39m# Manage errors in Layer rather than Trackable.\u001b[39;49;00m\n\u001b[0;32m    718\u001b[0m     overwrite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    719\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[0;32m    720\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    721\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m    722\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m    723\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[0;32m    724\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections_arg,\n\u001b[0;32m    725\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m    726\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m    727\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m    728\u001b[0m )\n\u001b[0;32m    729\u001b[0m \u001b[39mif\u001b[39;00m regularizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    730\u001b[0m     \u001b[39m# TODO(fchollet): in the future, this should be handled at the\u001b[39;00m\n\u001b[0;32m    731\u001b[0m     \u001b[39m# level of variable creation, and weight regularization losses\u001b[39;00m\n\u001b[0;32m    732\u001b[0m     \u001b[39m# should be variable attributes.\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     name_in_scope \u001b[39m=\u001b[39m variable\u001b[39m.\u001b[39mname[: variable\u001b[39m.\u001b[39mname\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m)]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\trackable\\base.py:489\u001b[0m, in \u001b[0;36mTrackable._add_variable_with_custom_getter\u001b[1;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[0;32m    479\u001b[0m   \u001b[39mif\u001b[39;00m (checkpoint_initializer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    480\u001b[0m       \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(initializer, CheckpointInitialValueCallable) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    481\u001b[0m            (initializer\u001b[39m.\u001b[39mrestore_uid \u001b[39m>\u001b[39m checkpoint_initializer\u001b[39m.\u001b[39mrestore_uid))):\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m     \u001b[39m# then we'll catch that when we call _track_trackable. So this is\u001b[39;00m\n\u001b[0;32m    487\u001b[0m     \u001b[39m# \"best effort\" to set the initializer with the highest restore UID.\u001b[39;00m\n\u001b[0;32m    488\u001b[0m     initializer \u001b[39m=\u001b[39m checkpoint_initializer\n\u001b[1;32m--> 489\u001b[0m new_variable \u001b[39m=\u001b[39m getter(\n\u001b[0;32m    490\u001b[0m     name\u001b[39m=\u001b[39mname,\n\u001b[0;32m    491\u001b[0m     shape\u001b[39m=\u001b[39mshape,\n\u001b[0;32m    492\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m    493\u001b[0m     initializer\u001b[39m=\u001b[39minitializer,\n\u001b[0;32m    494\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs_for_getter)\n\u001b[0;32m    496\u001b[0m \u001b[39m# If we set an initializer and the variable processed it, tracking will not\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[39m# assign again. It will add this variable to our dependencies, and if there\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \u001b[39m# is a non-trivial restoration queued, it will handle that. This also\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[39m# handles slot variables.\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m overwrite \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(new_variable, Trackable):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\base_layer_utils.py:134\u001b[0m, in \u001b[0;36mmake_variable\u001b[1;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner, layout)\u001b[0m\n\u001b[0;32m    127\u001b[0m     use_resource \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39mif\u001b[39;00m layout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     \u001b[39m# In theory, in `use_resource` is True and `collections` is empty\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     \u001b[39m# (that is to say, in TF2), we can use tf.Variable.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[39m# However, this breaks legacy (Estimator) checkpoints because\u001b[39;00m\n\u001b[0;32m    133\u001b[0m     \u001b[39m# it changes variable names. Remove this when V1 is fully deprecated.\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[39mreturn\u001b[39;00m tf1\u001b[39m.\u001b[39;49mVariable(\n\u001b[0;32m    135\u001b[0m         initial_value\u001b[39m=\u001b[39;49minit_val,\n\u001b[0;32m    136\u001b[0m         name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    137\u001b[0m         trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m    138\u001b[0m         caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m    139\u001b[0m         dtype\u001b[39m=\u001b[39;49mvariable_dtype,\n\u001b[0;32m    140\u001b[0m         validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[0;32m    141\u001b[0m         constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m    142\u001b[0m         use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[0;32m    143\u001b[0m         collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[0;32m    144\u001b[0m         synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m    145\u001b[0m         aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m    146\u001b[0m         shape\u001b[39m=\u001b[39;49mvariable_shape \u001b[39mif\u001b[39;49;00m variable_shape \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    147\u001b[0m     )\n\u001b[0;32m    148\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     \u001b[39mreturn\u001b[39;00m dtensor\u001b[39m.\u001b[39mDVariable(\n\u001b[0;32m    150\u001b[0m         initial_value\u001b[39m=\u001b[39minit_val,\n\u001b[0;32m    151\u001b[0m         name\u001b[39m=\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         shape\u001b[39m=\u001b[39mvariable_shape \u001b[39mif\u001b[39;00m variable_shape \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    161\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\ops\\variables.py:269\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[39m@traceback_utils\u001b[39m\u001b[39m.\u001b[39mfilter_traceback\n\u001b[0;32m    267\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    268\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m VariableV1:\n\u001b[1;32m--> 269\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_variable_v1_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    270\u001b[0m   \u001b[39melif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m Variable:\n\u001b[0;32m    271\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_variable_v2_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\ops\\variables.py:210\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v1_call\u001b[1;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[39mif\u001b[39;00m aggregation \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m   aggregation \u001b[39m=\u001b[39m VariableAggregation\u001b[39m.\u001b[39mNONE\n\u001b[1;32m--> 210\u001b[0m \u001b[39mreturn\u001b[39;00m previous_getter(\n\u001b[0;32m    211\u001b[0m     initial_value\u001b[39m=\u001b[39;49minitial_value,\n\u001b[0;32m    212\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m    213\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[0;32m    214\u001b[0m     validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[0;32m    215\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m    216\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    217\u001b[0m     variable_def\u001b[39m=\u001b[39;49mvariable_def,\n\u001b[0;32m    218\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    219\u001b[0m     expected_shape\u001b[39m=\u001b[39;49mexpected_shape,\n\u001b[0;32m    220\u001b[0m     import_scope\u001b[39m=\u001b[39;49mimport_scope,\n\u001b[0;32m    221\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m    222\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[0;32m    223\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m    224\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m    225\u001b[0m     shape\u001b[39m=\u001b[39;49mshape)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\ops\\variables.py:203\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v1_call.<locals>.<lambda>\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_variable_v1_call\u001b[39m(\u001b[39mcls\u001b[39m,\n\u001b[0;32m    187\u001b[0m                       initial_value\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    188\u001b[0m                       trainable\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m                       aggregation\u001b[39m=\u001b[39mVariableAggregation\u001b[39m.\u001b[39mNONE,\n\u001b[0;32m    201\u001b[0m                       shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    202\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m   previous_getter \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: default_variable_creator(\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    204\u001b[0m   \u001b[39mfor\u001b[39;00m _, getter \u001b[39min\u001b[39;00m ops\u001b[39m.\u001b[39mget_default_graph()\u001b[39m.\u001b[39m_variable_creator_stack:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    205\u001b[0m     previous_getter \u001b[39m=\u001b[39m _make_getter(getter, previous_getter)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\ops\\variable_scope.py:2706\u001b[0m, in \u001b[0;36mdefault_variable_creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   2704\u001b[0m \u001b[39mif\u001b[39;00m use_resource:\n\u001b[0;32m   2705\u001b[0m   distribute_strategy \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdistribute_strategy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 2706\u001b[0m   \u001b[39mreturn\u001b[39;00m resource_variable_ops\u001b[39m.\u001b[39;49mResourceVariable(\n\u001b[0;32m   2707\u001b[0m       initial_value\u001b[39m=\u001b[39;49minitial_value,\n\u001b[0;32m   2708\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m   2709\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[0;32m   2710\u001b[0m       validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[0;32m   2711\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m   2712\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   2713\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   2714\u001b[0m       constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m   2715\u001b[0m       variable_def\u001b[39m=\u001b[39;49mvariable_def,\n\u001b[0;32m   2716\u001b[0m       import_scope\u001b[39m=\u001b[39;49mimport_scope,\n\u001b[0;32m   2717\u001b[0m       distribute_strategy\u001b[39m=\u001b[39;49mdistribute_strategy,\n\u001b[0;32m   2718\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m   2719\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m   2720\u001b[0m       shape\u001b[39m=\u001b[39;49mshape)\n\u001b[0;32m   2721\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2722\u001b[0m   \u001b[39mreturn\u001b[39;00m variables\u001b[39m.\u001b[39mRefVariable(\n\u001b[0;32m   2723\u001b[0m       initial_value\u001b[39m=\u001b[39minitial_value,\n\u001b[0;32m   2724\u001b[0m       trainable\u001b[39m=\u001b[39mtrainable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2735\u001b[0m       aggregation\u001b[39m=\u001b[39maggregation,\n\u001b[0;32m   2736\u001b[0m       shape\u001b[39m=\u001b[39mshape)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\ops\\variables.py:273\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_variable_v2_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    272\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 273\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(VariableMetaclass, \u001b[39mcls\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1721\u001b[0m, in \u001b[0;36mResourceVariable.__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape, handle, experimental_enable_variable_lifting)\u001b[0m\n\u001b[0;32m   1716\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_handle(trainable\u001b[39m=\u001b[39mtrainable,\n\u001b[0;32m   1717\u001b[0m                          shape\u001b[39m=\u001b[39mshape,\n\u001b[0;32m   1718\u001b[0m                          dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   1719\u001b[0m                          handle\u001b[39m=\u001b[39mhandle)\n\u001b[0;32m   1720\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1721\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_from_args(\n\u001b[0;32m   1722\u001b[0m       initial_value\u001b[39m=\u001b[39;49minitial_value,\n\u001b[0;32m   1723\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[0;32m   1724\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[0;32m   1725\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[0;32m   1726\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   1727\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1728\u001b[0m       constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[0;32m   1729\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[0;32m   1730\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation,\n\u001b[0;32m   1731\u001b[0m       shape\u001b[39m=\u001b[39;49mshape,\n\u001b[0;32m   1732\u001b[0m       distribute_strategy\u001b[39m=\u001b[39;49mdistribute_strategy,\n\u001b[0;32m   1733\u001b[0m       validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[0;32m   1734\u001b[0m       experimental_enable_variable_lifting\u001b[39m=\u001b[39;49mexperimental_enable_variable_lifting,\n\u001b[0;32m   1735\u001b[0m       )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1905\u001b[0m, in \u001b[0;36mResourceVariable._init_from_args\u001b[1;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape, validate_shape, experimental_enable_variable_lifting)\u001b[0m\n\u001b[0;32m   1903\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(\u001b[39m\"\u001b[39m\u001b[39mInitializer\u001b[39m\u001b[39m\"\u001b[39m), device_context_manager(\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1904\u001b[0m   \u001b[39mif\u001b[39;00m init_from_fn:\n\u001b[1;32m-> 1905\u001b[0m     initial_value \u001b[39m=\u001b[39m initial_value()\n\u001b[0;32m   1906\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(initial_value, trackable\u001b[39m.\u001b[39mCheckpointInitialValue):\n\u001b[0;32m   1907\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_initialize_trackable()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\initializers\\initializers_v2.py:637\u001b[0m, in \u001b[0;36mVarianceScaling.__call__\u001b[1;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    629\u001b[0m     _ensure_keras_seeded()\n\u001b[0;32m    630\u001b[0m     \u001b[39mreturn\u001b[39;00m utils\u001b[39m.\u001b[39mcall_with_layout(\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_init_val,\n\u001b[0;32m    632\u001b[0m         layout,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    635\u001b[0m         nonce\u001b[39m=\u001b[39mnonce,\n\u001b[0;32m    636\u001b[0m     )\n\u001b[1;32m--> 637\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_init_val(shape\u001b[39m=\u001b[39;49mshape, dtype\u001b[39m=\u001b[39;49mdtype, nonce\u001b[39m=\u001b[39;49mnonce)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\initializers\\initializers_v2.py:662\u001b[0m, in \u001b[0;36mVarianceScaling._generate_init_val\u001b[1;34m(self, shape, dtype, nonce)\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    661\u001b[0m     limit \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39msqrt(\u001b[39m3.0\u001b[39m \u001b[39m*\u001b[39m scale)\n\u001b[1;32m--> 662\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_random_generator\u001b[39m.\u001b[39;49mrandom_uniform(\n\u001b[0;32m    663\u001b[0m         shape, \u001b[39m-\u001b[39;49mlimit, limit, dtype, nonce\n\u001b[0;32m    664\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\backend.py:2100\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[1;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[0;32m   2098\u001b[0m     \u001b[39mif\u001b[39;00m nonce:\n\u001b[0;32m   2099\u001b[0m         seed \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[1;32m-> 2100\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mstateless_uniform(\n\u001b[0;32m   2101\u001b[0m         shape\u001b[39m=\u001b[39;49mshape,\n\u001b[0;32m   2102\u001b[0m         minval\u001b[39m=\u001b[39;49mminval,\n\u001b[0;32m   2103\u001b[0m         maxval\u001b[39m=\u001b[39;49mmaxval,\n\u001b[0;32m   2104\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   2105\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[0;32m   2106\u001b[0m     )\n\u001b[0;32m   2107\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(\n\u001b[0;32m   2108\u001b[0m     shape\u001b[39m=\u001b[39mshape,\n\u001b[0;32m   2109\u001b[0m     minval\u001b[39m=\u001b[39mminval,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2112\u001b[0m     seed\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_legacy_seed(),\n\u001b[0;32m   2113\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\ops\\stateless_random_ops.py:501\u001b[0m, in \u001b[0;36mstateless_random_uniform\u001b[1;34m(shape, seed, minval, maxval, dtype, name, alg)\u001b[0m\n\u001b[0;32m    499\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m     key, counter, alg \u001b[39m=\u001b[39m _get_key_counter_alg(seed, alg)\n\u001b[1;32m--> 501\u001b[0m     rnd \u001b[39m=\u001b[39m gen_stateless_random_ops_v2\u001b[39m.\u001b[39;49mstateless_random_uniform_v2(\n\u001b[0;32m    502\u001b[0m         shape, key\u001b[39m=\u001b[39;49mkey, counter\u001b[39m=\u001b[39;49mcounter, dtype\u001b[39m=\u001b[39;49mdtype, alg\u001b[39m=\u001b[39;49malg)\n\u001b[0;32m    503\u001b[0m     result \u001b[39m=\u001b[39m math_ops\u001b[39m.\u001b[39madd(rnd \u001b[39m*\u001b[39m (maxval \u001b[39m-\u001b[39m minval), minval, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m    504\u001b[0m tensor_util\u001b[39m.\u001b[39mmaybe_set_static_shape(result, shape)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\ops\\gen_stateless_random_ops_v2.py:483\u001b[0m, in \u001b[0;36mstateless_random_uniform_v2\u001b[1;34m(shape, key, counter, alg, dtype, name)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m    482\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 483\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m    484\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mStatelessRandomUniformV2\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, shape, key, counter, alg,\n\u001b[0;32m    485\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mdtype\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype)\n\u001b[0;32m    486\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m    487\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define a new model with random weights and 10 classes\n",
    "new_input = Input(shape=(640, 480, 3))\n",
    "model = VGG16(weights=None, input_tensor=new_input, classes=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are familiar with the API, let’s take a look at loading three models using the Keras Applications API."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the VGG16 Pre-trained Model\n",
    "\n",
    "The VGG16 model was developed by the Visual Graphics Group (VGG) at Oxford and was described in the 2014 paper titled [“**Very Deep Convolutional Networks for Large-Scale Image Recognition**”](https://arxiv.org/abs/1409.1556).\n",
    "\n",
    "By default, the model expects color input images to be rescaled to the size of 224×224 squares.\n",
    "\n",
    "The model can be loaded as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# example of loading the vgg16 model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "# load model\n",
    "model = VGG16()\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example will load the VGG16 model and download the model weights if required.\n",
    "\n",
    "The model can then be used directly to classify a photograph into one of 1,000 classes. In this case, the model architecture is summarized to confirm that it was loaded correctly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the InceptionV3 Pre-Trained Model\n",
    "\n",
    "The InceptionV3 is the third iteration of the inception architecture, first developed for the GoogLeNet model.\n",
    "\n",
    "This model was developed by researchers at Google and described in the 2015 paper titled [“**Rethinking the Inception Architecture for Computer Vision**”](https://arxiv.org/abs/1512.00567).\n",
    "\n",
    "The model expects color images to have the square shape 299×299.\n",
    "\n",
    "The model can be loaded as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)             (None, 149, 149, 32  864         ['input_8[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_94 (BatchN  (None, 149, 149, 32  96         ['conv2d_94[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_94 (Activation)     (None, 149, 149, 32  0           ['batch_normalization_94[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)             (None, 147, 147, 32  9216        ['activation_94[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_95 (BatchN  (None, 147, 147, 32  96         ['conv2d_95[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_95 (Activation)     (None, 147, 147, 32  0           ['batch_normalization_95[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)             (None, 147, 147, 64  18432       ['activation_95[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_96 (BatchN  (None, 147, 147, 64  192        ['conv2d_96[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_96 (Activation)     (None, 147, 147, 64  0           ['batch_normalization_96[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 73, 73, 64)  0           ['activation_96[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)             (None, 73, 73, 80)   5120        ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_97 (BatchN  (None, 73, 73, 80)  240         ['conv2d_97[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_97 (Activation)     (None, 73, 73, 80)   0           ['batch_normalization_97[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)             (None, 71, 71, 192)  138240      ['activation_97[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_98 (BatchN  (None, 71, 71, 192)  576        ['conv2d_98[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_98 (Activation)     (None, 71, 71, 192)  0           ['batch_normalization_98[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 35, 35, 192)  0          ['activation_98[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_102 (Conv2D)            (None, 35, 35, 64)   12288       ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_102 (Batch  (None, 35, 35, 64)  192         ['conv2d_102[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_102 (Activation)    (None, 35, 35, 64)   0           ['batch_normalization_102[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_100 (Conv2D)            (None, 35, 35, 48)   9216        ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_103 (Conv2D)            (None, 35, 35, 96)   55296       ['activation_102[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_100 (Batch  (None, 35, 35, 48)  144         ['conv2d_100[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_103 (Batch  (None, 35, 35, 96)  288         ['conv2d_103[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_100 (Activation)    (None, 35, 35, 48)   0           ['batch_normalization_100[0][0]']\n",
      "                                                                                                  \n",
      " activation_103 (Activation)    (None, 35, 35, 96)   0           ['batch_normalization_103[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_9 (AveragePo  (None, 35, 35, 192)  0          ['max_pooling2d_5[0][0]']        \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)             (None, 35, 35, 64)   12288       ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_101 (Conv2D)            (None, 35, 35, 64)   76800       ['activation_100[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_104 (Conv2D)            (None, 35, 35, 96)   82944       ['activation_103[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_105 (Conv2D)            (None, 35, 35, 32)   6144        ['average_pooling2d_9[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_99 (BatchN  (None, 35, 35, 64)  192         ['conv2d_99[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_101 (Batch  (None, 35, 35, 64)  192         ['conv2d_101[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_104 (Batch  (None, 35, 35, 96)  288         ['conv2d_104[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_105 (Batch  (None, 35, 35, 32)  96          ['conv2d_105[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_99 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_99[0][0]'] \n",
      "                                                                                                  \n",
      " activation_101 (Activation)    (None, 35, 35, 64)   0           ['batch_normalization_101[0][0]']\n",
      "                                                                                                  \n",
      " activation_104 (Activation)    (None, 35, 35, 96)   0           ['batch_normalization_104[0][0]']\n",
      "                                                                                                  \n",
      " activation_105 (Activation)    (None, 35, 35, 32)   0           ['batch_normalization_105[0][0]']\n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 35, 35, 256)  0           ['activation_99[0][0]',          \n",
      "                                                                  'activation_101[0][0]',         \n",
      "                                                                  'activation_104[0][0]',         \n",
      "                                                                  'activation_105[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_109 (Conv2D)            (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_109 (Batch  (None, 35, 35, 64)  192         ['conv2d_109[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_109 (Activation)    (None, 35, 35, 64)   0           ['batch_normalization_109[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_107 (Conv2D)            (None, 35, 35, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_110 (Conv2D)            (None, 35, 35, 96)   55296       ['activation_109[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_107 (Batch  (None, 35, 35, 48)  144         ['conv2d_107[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_110 (Batch  (None, 35, 35, 96)  288         ['conv2d_110[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_107 (Activation)    (None, 35, 35, 48)   0           ['batch_normalization_107[0][0]']\n",
      "                                                                                                  \n",
      " activation_110 (Activation)    (None, 35, 35, 96)   0           ['batch_normalization_110[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_10 (AverageP  (None, 35, 35, 256)  0          ['mixed0[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_106 (Conv2D)            (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_108 (Conv2D)            (None, 35, 35, 64)   76800       ['activation_107[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_111 (Conv2D)            (None, 35, 35, 96)   82944       ['activation_110[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)            (None, 35, 35, 64)   16384       ['average_pooling2d_10[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_106 (Batch  (None, 35, 35, 64)  192         ['conv2d_106[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_108 (Batch  (None, 35, 35, 64)  192         ['conv2d_108[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_111 (Batch  (None, 35, 35, 96)  288         ['conv2d_111[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_112 (Batch  (None, 35, 35, 64)  192         ['conv2d_112[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_106 (Activation)    (None, 35, 35, 64)   0           ['batch_normalization_106[0][0]']\n",
      "                                                                                                  \n",
      " activation_108 (Activation)    (None, 35, 35, 64)   0           ['batch_normalization_108[0][0]']\n",
      "                                                                                                  \n",
      " activation_111 (Activation)    (None, 35, 35, 96)   0           ['batch_normalization_111[0][0]']\n",
      "                                                                                                  \n",
      " activation_112 (Activation)    (None, 35, 35, 64)   0           ['batch_normalization_112[0][0]']\n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 35, 35, 288)  0           ['activation_106[0][0]',         \n",
      "                                                                  'activation_108[0][0]',         \n",
      "                                                                  'activation_111[0][0]',         \n",
      "                                                                  'activation_112[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_116 (Conv2D)            (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_116 (Batch  (None, 35, 35, 64)  192         ['conv2d_116[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_116 (Activation)    (None, 35, 35, 64)   0           ['batch_normalization_116[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_114 (Conv2D)            (None, 35, 35, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_117 (Conv2D)            (None, 35, 35, 96)   55296       ['activation_116[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_114 (Batch  (None, 35, 35, 48)  144         ['conv2d_114[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_117 (Batch  (None, 35, 35, 96)  288         ['conv2d_117[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_114 (Activation)    (None, 35, 35, 48)   0           ['batch_normalization_114[0][0]']\n",
      "                                                                                                  \n",
      " activation_117 (Activation)    (None, 35, 35, 96)   0           ['batch_normalization_117[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_11 (AverageP  (None, 35, 35, 288)  0          ['mixed1[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_113 (Conv2D)            (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_115 (Conv2D)            (None, 35, 35, 64)   76800       ['activation_114[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_118 (Conv2D)            (None, 35, 35, 96)   82944       ['activation_117[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_119 (Conv2D)            (None, 35, 35, 64)   18432       ['average_pooling2d_11[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_113 (Batch  (None, 35, 35, 64)  192         ['conv2d_113[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_115 (Batch  (None, 35, 35, 64)  192         ['conv2d_115[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_118 (Batch  (None, 35, 35, 96)  288         ['conv2d_118[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_119 (Batch  (None, 35, 35, 64)  192         ['conv2d_119[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_113 (Activation)    (None, 35, 35, 64)   0           ['batch_normalization_113[0][0]']\n",
      "                                                                                                  \n",
      " activation_115 (Activation)    (None, 35, 35, 64)   0           ['batch_normalization_115[0][0]']\n",
      "                                                                                                  \n",
      " activation_118 (Activation)    (None, 35, 35, 96)   0           ['batch_normalization_118[0][0]']\n",
      "                                                                                                  \n",
      " activation_119 (Activation)    (None, 35, 35, 64)   0           ['batch_normalization_119[0][0]']\n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 35, 35, 288)  0           ['activation_113[0][0]',         \n",
      "                                                                  'activation_115[0][0]',         \n",
      "                                                                  'activation_118[0][0]',         \n",
      "                                                                  'activation_119[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_121 (Conv2D)            (None, 35, 35, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_121 (Batch  (None, 35, 35, 64)  192         ['conv2d_121[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_121 (Activation)    (None, 35, 35, 64)   0           ['batch_normalization_121[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_122 (Conv2D)            (None, 35, 35, 96)   55296       ['activation_121[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_122 (Batch  (None, 35, 35, 96)  288         ['conv2d_122[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_122 (Activation)    (None, 35, 35, 96)   0           ['batch_normalization_122[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_120 (Conv2D)            (None, 17, 17, 384)  995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_123 (Conv2D)            (None, 17, 17, 96)   82944       ['activation_122[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_120 (Batch  (None, 17, 17, 384)  1152       ['conv2d_120[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_123 (Batch  (None, 17, 17, 96)  288         ['conv2d_123[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_120 (Activation)    (None, 17, 17, 384)  0           ['batch_normalization_120[0][0]']\n",
      "                                                                                                  \n",
      " activation_123 (Activation)    (None, 17, 17, 96)   0           ['batch_normalization_123[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 17, 17, 288)  0          ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 17, 17, 768)  0           ['activation_120[0][0]',         \n",
      "                                                                  'activation_123[0][0]',         \n",
      "                                                                  'max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)            (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_128 (Batch  (None, 17, 17, 128)  384        ['conv2d_128[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_128 (Activation)    (None, 17, 17, 128)  0           ['batch_normalization_128[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)            (None, 17, 17, 128)  114688      ['activation_128[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_129 (Batch  (None, 17, 17, 128)  384        ['conv2d_129[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_129 (Activation)    (None, 17, 17, 128)  0           ['batch_normalization_129[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_125 (Conv2D)            (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)            (None, 17, 17, 128)  114688      ['activation_129[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_125 (Batch  (None, 17, 17, 128)  384        ['conv2d_125[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_130 (Batch  (None, 17, 17, 128)  384        ['conv2d_130[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_125 (Activation)    (None, 17, 17, 128)  0           ['batch_normalization_125[0][0]']\n",
      "                                                                                                  \n",
      " activation_130 (Activation)    (None, 17, 17, 128)  0           ['batch_normalization_130[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)            (None, 17, 17, 128)  114688      ['activation_125[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_131 (Conv2D)            (None, 17, 17, 128)  114688      ['activation_130[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_126 (Batch  (None, 17, 17, 128)  384        ['conv2d_126[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_131 (Batch  (None, 17, 17, 128)  384        ['conv2d_131[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_126 (Activation)    (None, 17, 17, 128)  0           ['batch_normalization_126[0][0]']\n",
      "                                                                                                  \n",
      " activation_131 (Activation)    (None, 17, 17, 128)  0           ['batch_normalization_131[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_12 (AverageP  (None, 17, 17, 768)  0          ['mixed3[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_124 (Conv2D)            (None, 17, 17, 192)  147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)            (None, 17, 17, 192)  172032      ['activation_126[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_132 (Conv2D)            (None, 17, 17, 192)  172032      ['activation_131[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_133 (Conv2D)            (None, 17, 17, 192)  147456      ['average_pooling2d_12[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_124 (Batch  (None, 17, 17, 192)  576        ['conv2d_124[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_127 (Batch  (None, 17, 17, 192)  576        ['conv2d_127[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_132 (Batch  (None, 17, 17, 192)  576        ['conv2d_132[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_133 (Batch  (None, 17, 17, 192)  576        ['conv2d_133[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_124 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_124[0][0]']\n",
      "                                                                                                  \n",
      " activation_127 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_127[0][0]']\n",
      "                                                                                                  \n",
      " activation_132 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_132[0][0]']\n",
      "                                                                                                  \n",
      " activation_133 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_133[0][0]']\n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 17, 17, 768)  0           ['activation_124[0][0]',         \n",
      "                                                                  'activation_127[0][0]',         \n",
      "                                                                  'activation_132[0][0]',         \n",
      "                                                                  'activation_133[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_138 (Conv2D)            (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_138 (Batch  (None, 17, 17, 160)  480        ['conv2d_138[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_138 (Activation)    (None, 17, 17, 160)  0           ['batch_normalization_138[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_139 (Conv2D)            (None, 17, 17, 160)  179200      ['activation_138[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_139 (Batch  (None, 17, 17, 160)  480        ['conv2d_139[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_139 (Activation)    (None, 17, 17, 160)  0           ['batch_normalization_139[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_135 (Conv2D)            (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_140 (Conv2D)            (None, 17, 17, 160)  179200      ['activation_139[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_135 (Batch  (None, 17, 17, 160)  480        ['conv2d_135[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_140 (Batch  (None, 17, 17, 160)  480        ['conv2d_140[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_135 (Activation)    (None, 17, 17, 160)  0           ['batch_normalization_135[0][0]']\n",
      "                                                                                                  \n",
      " activation_140 (Activation)    (None, 17, 17, 160)  0           ['batch_normalization_140[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_136 (Conv2D)            (None, 17, 17, 160)  179200      ['activation_135[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_141 (Conv2D)            (None, 17, 17, 160)  179200      ['activation_140[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_136 (Batch  (None, 17, 17, 160)  480        ['conv2d_136[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_141 (Batch  (None, 17, 17, 160)  480        ['conv2d_141[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_136 (Activation)    (None, 17, 17, 160)  0           ['batch_normalization_136[0][0]']\n",
      "                                                                                                  \n",
      " activation_141 (Activation)    (None, 17, 17, 160)  0           ['batch_normalization_141[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_13 (AverageP  (None, 17, 17, 768)  0          ['mixed4[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_134 (Conv2D)            (None, 17, 17, 192)  147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_137 (Conv2D)            (None, 17, 17, 192)  215040      ['activation_136[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_142 (Conv2D)            (None, 17, 17, 192)  215040      ['activation_141[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_143 (Conv2D)            (None, 17, 17, 192)  147456      ['average_pooling2d_13[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_134 (Batch  (None, 17, 17, 192)  576        ['conv2d_134[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_137 (Batch  (None, 17, 17, 192)  576        ['conv2d_137[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_142 (Batch  (None, 17, 17, 192)  576        ['conv2d_142[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_143 (Batch  (None, 17, 17, 192)  576        ['conv2d_143[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_134 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_134[0][0]']\n",
      "                                                                                                  \n",
      " activation_137 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_137[0][0]']\n",
      "                                                                                                  \n",
      " activation_142 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_142[0][0]']\n",
      "                                                                                                  \n",
      " activation_143 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_143[0][0]']\n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 17, 17, 768)  0           ['activation_134[0][0]',         \n",
      "                                                                  'activation_137[0][0]',         \n",
      "                                                                  'activation_142[0][0]',         \n",
      "                                                                  'activation_143[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_148 (Conv2D)            (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_148 (Batch  (None, 17, 17, 160)  480        ['conv2d_148[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_148 (Activation)    (None, 17, 17, 160)  0           ['batch_normalization_148[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_149 (Conv2D)            (None, 17, 17, 160)  179200      ['activation_148[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_149 (Batch  (None, 17, 17, 160)  480        ['conv2d_149[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_149 (Activation)    (None, 17, 17, 160)  0           ['batch_normalization_149[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_145 (Conv2D)            (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_150 (Conv2D)            (None, 17, 17, 160)  179200      ['activation_149[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_145 (Batch  (None, 17, 17, 160)  480        ['conv2d_145[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_150 (Batch  (None, 17, 17, 160)  480        ['conv2d_150[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_145 (Activation)    (None, 17, 17, 160)  0           ['batch_normalization_145[0][0]']\n",
      "                                                                                                  \n",
      " activation_150 (Activation)    (None, 17, 17, 160)  0           ['batch_normalization_150[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_146 (Conv2D)            (None, 17, 17, 160)  179200      ['activation_145[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_151 (Conv2D)            (None, 17, 17, 160)  179200      ['activation_150[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_146 (Batch  (None, 17, 17, 160)  480        ['conv2d_146[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_151 (Batch  (None, 17, 17, 160)  480        ['conv2d_151[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_146 (Activation)    (None, 17, 17, 160)  0           ['batch_normalization_146[0][0]']\n",
      "                                                                                                  \n",
      " activation_151 (Activation)    (None, 17, 17, 160)  0           ['batch_normalization_151[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_14 (AverageP  (None, 17, 17, 768)  0          ['mixed5[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_144 (Conv2D)            (None, 17, 17, 192)  147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_147 (Conv2D)            (None, 17, 17, 192)  215040      ['activation_146[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_152 (Conv2D)            (None, 17, 17, 192)  215040      ['activation_151[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_153 (Conv2D)            (None, 17, 17, 192)  147456      ['average_pooling2d_14[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_144 (Batch  (None, 17, 17, 192)  576        ['conv2d_144[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_147 (Batch  (None, 17, 17, 192)  576        ['conv2d_147[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_152 (Batch  (None, 17, 17, 192)  576        ['conv2d_152[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_153 (Batch  (None, 17, 17, 192)  576        ['conv2d_153[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_144 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_144[0][0]']\n",
      "                                                                                                  \n",
      " activation_147 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_147[0][0]']\n",
      "                                                                                                  \n",
      " activation_152 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_152[0][0]']\n",
      "                                                                                                  \n",
      " activation_153 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_153[0][0]']\n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 17, 17, 768)  0           ['activation_144[0][0]',         \n",
      "                                                                  'activation_147[0][0]',         \n",
      "                                                                  'activation_152[0][0]',         \n",
      "                                                                  'activation_153[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_158 (Conv2D)            (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_158 (Batch  (None, 17, 17, 192)  576        ['conv2d_158[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_158 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_158[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_159 (Conv2D)            (None, 17, 17, 192)  258048      ['activation_158[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_159 (Batch  (None, 17, 17, 192)  576        ['conv2d_159[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_159 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_159[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_155 (Conv2D)            (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_160 (Conv2D)            (None, 17, 17, 192)  258048      ['activation_159[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_155 (Batch  (None, 17, 17, 192)  576        ['conv2d_155[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_160 (Batch  (None, 17, 17, 192)  576        ['conv2d_160[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_155 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_155[0][0]']\n",
      "                                                                                                  \n",
      " activation_160 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_160[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_156 (Conv2D)            (None, 17, 17, 192)  258048      ['activation_155[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_161 (Conv2D)            (None, 17, 17, 192)  258048      ['activation_160[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_156 (Batch  (None, 17, 17, 192)  576        ['conv2d_156[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_161 (Batch  (None, 17, 17, 192)  576        ['conv2d_161[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_156 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_156[0][0]']\n",
      "                                                                                                  \n",
      " activation_161 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_161[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_15 (AverageP  (None, 17, 17, 768)  0          ['mixed6[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_154 (Conv2D)            (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_157 (Conv2D)            (None, 17, 17, 192)  258048      ['activation_156[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_162 (Conv2D)            (None, 17, 17, 192)  258048      ['activation_161[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_163 (Conv2D)            (None, 17, 17, 192)  147456      ['average_pooling2d_15[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_154 (Batch  (None, 17, 17, 192)  576        ['conv2d_154[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_157 (Batch  (None, 17, 17, 192)  576        ['conv2d_157[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_162 (Batch  (None, 17, 17, 192)  576        ['conv2d_162[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_163 (Batch  (None, 17, 17, 192)  576        ['conv2d_163[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_154 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_154[0][0]']\n",
      "                                                                                                  \n",
      " activation_157 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_157[0][0]']\n",
      "                                                                                                  \n",
      " activation_162 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_162[0][0]']\n",
      "                                                                                                  \n",
      " activation_163 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_163[0][0]']\n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 17, 17, 768)  0           ['activation_154[0][0]',         \n",
      "                                                                  'activation_157[0][0]',         \n",
      "                                                                  'activation_162[0][0]',         \n",
      "                                                                  'activation_163[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_166 (Conv2D)            (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_166 (Batch  (None, 17, 17, 192)  576        ['conv2d_166[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_166 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_166[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_167 (Conv2D)            (None, 17, 17, 192)  258048      ['activation_166[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_167 (Batch  (None, 17, 17, 192)  576        ['conv2d_167[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_167 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_167[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_164 (Conv2D)            (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_168 (Conv2D)            (None, 17, 17, 192)  258048      ['activation_167[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_164 (Batch  (None, 17, 17, 192)  576        ['conv2d_164[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_168 (Batch  (None, 17, 17, 192)  576        ['conv2d_168[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_164 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_164[0][0]']\n",
      "                                                                                                  \n",
      " activation_168 (Activation)    (None, 17, 17, 192)  0           ['batch_normalization_168[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_165 (Conv2D)            (None, 8, 8, 320)    552960      ['activation_164[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_169 (Conv2D)            (None, 8, 8, 192)    331776      ['activation_168[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_165 (Batch  (None, 8, 8, 320)   960         ['conv2d_165[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_169 (Batch  (None, 8, 8, 192)   576         ['conv2d_169[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_165 (Activation)    (None, 8, 8, 320)    0           ['batch_normalization_165[0][0]']\n",
      "                                                                                                  \n",
      " activation_169 (Activation)    (None, 8, 8, 192)    0           ['batch_normalization_169[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 8, 8, 1280)   0           ['activation_165[0][0]',         \n",
      "                                                                  'activation_169[0][0]',         \n",
      "                                                                  'max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_174 (Conv2D)            (None, 8, 8, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_174 (Batch  (None, 8, 8, 448)   1344        ['conv2d_174[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_174 (Activation)    (None, 8, 8, 448)    0           ['batch_normalization_174[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_171 (Conv2D)            (None, 8, 8, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_175 (Conv2D)            (None, 8, 8, 384)    1548288     ['activation_174[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_171 (Batch  (None, 8, 8, 384)   1152        ['conv2d_171[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_175 (Batch  (None, 8, 8, 384)   1152        ['conv2d_175[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_171 (Activation)    (None, 8, 8, 384)    0           ['batch_normalization_171[0][0]']\n",
      "                                                                                                  \n",
      " activation_175 (Activation)    (None, 8, 8, 384)    0           ['batch_normalization_175[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_172 (Conv2D)            (None, 8, 8, 384)    442368      ['activation_171[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_173 (Conv2D)            (None, 8, 8, 384)    442368      ['activation_171[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_176 (Conv2D)            (None, 8, 8, 384)    442368      ['activation_175[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_177 (Conv2D)            (None, 8, 8, 384)    442368      ['activation_175[0][0]']         \n",
      "                                                                                                  \n",
      " average_pooling2d_16 (AverageP  (None, 8, 8, 1280)  0           ['mixed8[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_170 (Conv2D)            (None, 8, 8, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_172 (Batch  (None, 8, 8, 384)   1152        ['conv2d_172[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_173 (Batch  (None, 8, 8, 384)   1152        ['conv2d_173[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_176 (Batch  (None, 8, 8, 384)   1152        ['conv2d_176[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_177 (Batch  (None, 8, 8, 384)   1152        ['conv2d_177[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_178 (Conv2D)            (None, 8, 8, 192)    245760      ['average_pooling2d_16[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_170 (Batch  (None, 8, 8, 320)   960         ['conv2d_170[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_172 (Activation)    (None, 8, 8, 384)    0           ['batch_normalization_172[0][0]']\n",
      "                                                                                                  \n",
      " activation_173 (Activation)    (None, 8, 8, 384)    0           ['batch_normalization_173[0][0]']\n",
      "                                                                                                  \n",
      " activation_176 (Activation)    (None, 8, 8, 384)    0           ['batch_normalization_176[0][0]']\n",
      "                                                                                                  \n",
      " activation_177 (Activation)    (None, 8, 8, 384)    0           ['batch_normalization_177[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_178 (Batch  (None, 8, 8, 192)   576         ['conv2d_178[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_170 (Activation)    (None, 8, 8, 320)    0           ['batch_normalization_170[0][0]']\n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 8, 8, 768)    0           ['activation_172[0][0]',         \n",
      "                                                                  'activation_173[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 8, 8, 768)    0           ['activation_176[0][0]',         \n",
      "                                                                  'activation_177[0][0]']         \n",
      "                                                                                                  \n",
      " activation_178 (Activation)    (None, 8, 8, 192)    0           ['batch_normalization_178[0][0]']\n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 8, 8, 2048)   0           ['activation_170[0][0]',         \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate_2[0][0]',          \n",
      "                                                                  'activation_178[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_183 (Conv2D)            (None, 8, 8, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_183 (Batch  (None, 8, 8, 448)   1344        ['conv2d_183[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_183 (Activation)    (None, 8, 8, 448)    0           ['batch_normalization_183[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_180 (Conv2D)            (None, 8, 8, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_184 (Conv2D)            (None, 8, 8, 384)    1548288     ['activation_183[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_180 (Batch  (None, 8, 8, 384)   1152        ['conv2d_180[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_184 (Batch  (None, 8, 8, 384)   1152        ['conv2d_184[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_180 (Activation)    (None, 8, 8, 384)    0           ['batch_normalization_180[0][0]']\n",
      "                                                                                                  \n",
      " activation_184 (Activation)    (None, 8, 8, 384)    0           ['batch_normalization_184[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_181 (Conv2D)            (None, 8, 8, 384)    442368      ['activation_180[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_182 (Conv2D)            (None, 8, 8, 384)    442368      ['activation_180[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_185 (Conv2D)            (None, 8, 8, 384)    442368      ['activation_184[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_186 (Conv2D)            (None, 8, 8, 384)    442368      ['activation_184[0][0]']         \n",
      "                                                                                                  \n",
      " average_pooling2d_17 (AverageP  (None, 8, 8, 2048)  0           ['mixed9[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_179 (Conv2D)            (None, 8, 8, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_181 (Batch  (None, 8, 8, 384)   1152        ['conv2d_181[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_182 (Batch  (None, 8, 8, 384)   1152        ['conv2d_182[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_185 (Batch  (None, 8, 8, 384)   1152        ['conv2d_185[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_186 (Batch  (None, 8, 8, 384)   1152        ['conv2d_186[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_187 (Conv2D)            (None, 8, 8, 192)    393216      ['average_pooling2d_17[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_179 (Batch  (None, 8, 8, 320)   960         ['conv2d_179[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_181 (Activation)    (None, 8, 8, 384)    0           ['batch_normalization_181[0][0]']\n",
      "                                                                                                  \n",
      " activation_182 (Activation)    (None, 8, 8, 384)    0           ['batch_normalization_182[0][0]']\n",
      "                                                                                                  \n",
      " activation_185 (Activation)    (None, 8, 8, 384)    0           ['batch_normalization_185[0][0]']\n",
      "                                                                                                  \n",
      " activation_186 (Activation)    (None, 8, 8, 384)    0           ['batch_normalization_186[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_187 (Batch  (None, 8, 8, 192)   576         ['conv2d_187[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_179 (Activation)    (None, 8, 8, 320)    0           ['batch_normalization_179[0][0]']\n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 8, 8, 768)    0           ['activation_181[0][0]',         \n",
      "                                                                  'activation_182[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 8, 8, 768)    0           ['activation_185[0][0]',         \n",
      "                                                                  'activation_186[0][0]']         \n",
      "                                                                                                  \n",
      " activation_187 (Activation)    (None, 8, 8, 192)    0           ['batch_normalization_187[0][0]']\n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 8, 8, 2048)   0           ['activation_179[0][0]',         \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_3[0][0]',          \n",
      "                                                                  'activation_187[0][0]']         \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['mixed10[0][0]']                \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 1000)         2049000     ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,851,784\n",
      "Trainable params: 23,817,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# example of loading the inception v3 model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "# load model\n",
    "model = InceptionV3()\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example will load the model, downloading the weights if required, and then summarize the model architecture to confirm it was loaded correctly.\n",
    "\n",
    "The output is omitted in this case for brevity, as it is a deep model with many layers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the ResNet50 Pre-trained Model\n",
    "\n",
    "The Residual Network, or ResNet for short, is a model that makes use of the residual module involving shortcut connections.\n",
    "\n",
    "It was developed by researchers at Microsoft and described in the 2015 paper titled [“**Deep Residual Learning for Image Recognition**”](https://arxiv.org/abs/1512.03385).\n",
    "\n",
    "The model expects color images to have the square shape 224×224."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102967424/102967424 [==============================] - 4s 0us/step\n",
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 1000)         2049000     ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# example of loading the resnet50 model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "# load model\n",
    "model = ResNet50()\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example will load the model, downloading the weights if required, and then summarize the model architecture to confirm it was loaded correctly.\n",
    "\n",
    "The output is omitted in this case for brevity, as it is a deep model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of Using Pre-Trained Models\n",
    "\n",
    "Now that we are familiar with how to load pre-trained models in Keras, let’s look at some examples of how they might be used in practice.\n",
    "\n",
    "In these examples, we will work with the VGG16 model as it is a relatively straightforward model to use and a simple model architecture to understand.\n",
    "\n",
    "We also need a photograph to work with in these examples. Below is a photograph of a dog, taken by Justin Morgan and made available under a permissive license.\n",
    "\n",
    "![](https://machinelearningmastery.com/wp-content/uploads/2019/02/dog.jpg)\n",
    "\n",
    "Download the photograph and place it in your current working directory with the filename `dog.jpg`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Trained Model as Classifier\n",
    "\n",
    "A pre-trained model can be used directly to classify new photographs as one of the 1,000 known classes in the image classification task in the ILSVRC.\n",
    "\n",
    "We will use the VGG16 model to classify new images.\n",
    "\n",
    "First, the photograph needs to loaded and reshaped to a 224×224 square, expected by the model, and the pixel values scaled in the way expected by the model. The model operates on an array of samples, therefore the dimensions of a loaded image need to be expanded by 1, for one image with 224×224 pixels and three channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import load_img, img_to_array\n",
    "# load an image from file\n",
    "image = load_img('dog.jpg', target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "# reshape data for the model\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "# prepare the image for the VGG model\n",
    "image = preprocess_input(image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the model can be loaded and a prediction made.\n",
    "\n",
    "This means that a predicted probability of the photo belonging to each of the 1,000 classes is made. In this example, we are only concerned with the most likely class, so we can decode the predictions and retrieve the label or name of the class with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 776ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16, decode_predictions\n",
    "# load model\n",
    "model = VGG16()\n",
    "# predict the probability across all output classes\n",
    "yhat = model.predict(image)\n",
    "# convert the probabilities to class labels\n",
    "label = decode_predictions(yhat)\n",
    "# retrieve the most likely result, e.g. highest probability\n",
    "label = label[0][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tying all of this together, the complete example below loads a new photograph and predicts the most likely class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001954C143010> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "golden_retriever (68.79%)\n"
     ]
    }
   ],
   "source": [
    "# example of using a pre-trained model as a classifier\n",
    "from keras.utils import load_img, img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "# load an image from file\n",
    "image = load_img('dog_2.jpg', target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "# reshape data for the model\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "# prepare the image for the VGG model\n",
    "image = preprocess_input(image)\n",
    "# load the model\n",
    "model = VGG16()\n",
    "# predict the probability across all output classes\n",
    "yhat = model.predict(image)\n",
    "# convert the probabilities to class labels\n",
    "label = decode_predictions(yhat)\n",
    "# retrieve the most likely result, e.g. highest probability\n",
    "label = label[0][0]\n",
    "# print the classification\n",
    "print('%s (%.2f%%)' % (label[1], label[2]*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example predicts more than just dog; it also predicts the specific breed of `Doberman` with a probability of 33.59%, which may, in fact, be correct."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Trained Model as Feature Extractor Preprocessor\n",
    "\n",
    "The pre-trained model may be used as a standalone program to extract features from new photographs.\n",
    "\n",
    "Specifically, the extracted features of a photograph may be a vector of numbers that the model will use to describe the specific features in a photograph. These features can then be used as input in the development of a new model.\n",
    "\n",
    "The last few layers of the VGG16 model are fully connected layers prior to the output layer. These layers will provide a complex set of features to describe a given input image and may provide useful input when training a new model for image classification or related computer vision task.\n",
    "\n",
    "The image can be loaded and prepared for the model, as we did before in the previous example.\n",
    "\n",
    "We will load the model with the classifier output part of the model, but manually remove the final output layer. This means that the second last fully connected layer with 4,096 nodes will be the new output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "# load model\n",
    "model = VGG16()\n",
    "# remove the output layer\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-2].output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This vector of 4,096 numbers will be used to represent the complex features of a given input image that can then be saved to file to be loaded later and used as input to train a new model. We can save it as a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001954C142B90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "(1, 4096)\n"
     ]
    }
   ],
   "source": [
    "from pickle import dump\n",
    "# get extracted features\n",
    "features = model.predict(image)\n",
    "print(features.shape)\n",
    "# save to file\n",
    "dump(features, open('dog.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tying all of this together, the complete example of using the model as a standalone feature extraction model is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 364ms/step\n",
      "(1, 4096)\n"
     ]
    }
   ],
   "source": [
    "# example of using the vgg16 model as a feature extraction model\n",
    "from keras.utils import load_img, img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "# from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from pickle import dump\n",
    "# load an image from file\n",
    "image = load_img('dog.jpg', target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "# reshape data for the model\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "# prepare the image for the VGG model\n",
    "image = preprocess_input(image)\n",
    "# load model\n",
    "model = VGG16()\n",
    "# remove the output layer\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "# get extracted features\n",
    "features = model.predict(image)\n",
    "print(features.shape)\n",
    "# save to file\n",
    "dump(features, open('dog.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example loads the photograph, then prepares the model as a feature extraction model.\n",
    "\n",
    "The features are extracted from the loaded photo and the shape of the feature vector is printed, showing it has 4,096 numbers. This feature is then saved to a new file `dog.pkl` in the current working directory.\n",
    "\n",
    "This process could be repeated for each photo in a new training dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Trained Model as Feature Extractor in Model\n",
    "\n",
    "We can use some or all of the layers in a pre-trained model as a feature extraction component of a new model directly.\n",
    "\n",
    "This can be achieved by loading the model, then simply adding new layers. This may involve adding new convolutional and pooling layers to expand upon the feature extraction capabilities of the model or adding new fully connected classifier type layers to learn how to interpret the extracted features on a new dataset, or some combination.\n",
    "\n",
    "For example, we can load the VGG16 models without the classifier part of the model by specifying the `include_top` argument to `False`, and specify the preferred shape of the images in our new dataset as 300×300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model without classifier layers\n",
    "model = VGG16(include_top=False, input_shape=(300, 300, 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the Keras function API to add a new Flatten layer after the last pooling layer in the VGG16 model, then define a new classifier model with a Dense fully connected layer and an output layer that will predict the probability for 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Dense\n",
    "# add new classifier layers\n",
    "flat1 = Flatten()(model.layers[-1].output)\n",
    "class1 = Dense(1024, activation='relu')(flat1)\n",
    "output = Dense(10, activation='softmax')(class1)\n",
    "# define new model\n",
    "model = Model(inputs=model.inputs, outputs=output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative approach to adding a Flatten layer would be to define the VGG16 model with an average pooling layer, and then add fully connected layers. Perhaps try both approaches on your application and see which results in the best performance.\n",
    "\n",
    "The weights of the VGG16 model and the weights for the new model will all be trained together on the new dataset.\n",
    "\n",
    "The complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_18 (InputLayer)       [(None, 300, 300, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 300, 300, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 300, 300, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 150, 150, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 150, 150, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 150, 150, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 75, 75, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 75, 75, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 75, 75, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 75, 75, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 37, 37, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 37, 37, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 37, 37, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 37, 37, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 18, 18, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 41472)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              42468352  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,193,290\n",
      "Trainable params: 57,193,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# example of tending the vgg16 model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten\n",
    "# load model without classifier layers\n",
    "model = VGG16(include_top=False, input_shape=(300, 300, 3))\n",
    "# add new classifier layers\n",
    "flat1 = Flatten()(model.layers[-1].output)\n",
    "class1 = Dense(1024, activation='relu')(flat1)\n",
    "output = Dense(10, activation='softmax')(class1)\n",
    "# define new model\n",
    "model = Model(inputs=model.inputs, outputs=output)\n",
    "# summarize\n",
    "model.summary()\n",
    "# ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example defines the new model ready for training and summarizes the model architecture.\n",
    "\n",
    "We can see that we have flattened the output of the last pooling layer and added our new fully connected layers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately, we may wish to use the VGG16 model layers, but train the new layers of the model without updating the weights of the VGG16 layers. This will allow the new output layers to learn to interpret the learned features of the VGG16 model.\n",
    "\n",
    "This can be achieved by setting the `trainable` property on each of the layers in the loaded VGG model to False prior to training. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model without classifier layers\n",
    "model = VGG16(include_top=False, input_shape=(300, 300, 3))\n",
    "# mark loaded layers as not trainable\n",
    "for layer in model.layers:\n",
    "\tlayer.trainable = False\n",
    "# ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pick and choose which layers are trainable.\n",
    "\n",
    "For example, perhaps you want to retrain some of the convolutional layers deep in the model, but none of the layers earlier in the model. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model without classifier layers\n",
    "model = VGG16(include_top=False, input_shape=(300, 300, 3))\n",
    "# mark some layers as not trainable\n",
    "model.get_layer('block1_conv1').trainable = False\n",
    "model.get_layer('block1_conv2').trainable = False\n",
    "model.get_layer('block2_conv1').trainable = False\n",
    "model.get_layer('block2_conv2').trainable = False\n",
    "# ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "This section provides more resources on the topic if you are looking to go deeper.\n",
    "\n",
    "My posts\n",
    "* [How to Improve Performance With Transfer Learning for Deep Learning Neural Networks](https://machinelearningmastery.com/how-to-improve-performance-with-transfer-learning-for-deep-learning-neural-networks/)\n",
    "* [A Gentle Introduction to Transfer Learning for Deep Learning](https://machinelearningmastery.com/transfer-learning-for-deep-learning/)\n",
    "* [How to Use The Pre-Trained VGG Model to Classify Objects in Photographs](https://machinelearningmastery.com/use-pre-trained-vgg-model-classify-objects-photographs/)\n",
    "\n",
    "Papers\n",
    "* [**A Survey on Transfer Learning, 2010**](https://ieeexplore.ieee.org/document/5288526).\n",
    "* [**How transferable are features in deep neural networks?**](https://arxiv.org/abs/1411.1792), 2014.\n",
    "* [**CNN features off-the-shelf: An astounding baseline for recognition**](https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2014/W15/html/Razavian_CNN_Features_Off-the-Shelf_2014_CVPR_paper.html), 2014.\n",
    "\n",
    "APIs\n",
    "* [Keras Applications API](https://keras.io/api/applications/)\n",
    "\n",
    "Articles\n",
    "* [**Transfer Learning**](https://en.wikipedia.org/wiki/Transfer_learning), Wikipedia.\n",
    "* [**Transfer Learning**](https://www.ruder.io/transfer-learning/) – Machine Learning’s Next Frontier, 2017.\n",
    "\n",
    "My book\n",
    "* Deep Learning, 2016.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
