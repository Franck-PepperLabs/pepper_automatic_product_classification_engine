{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Gestion du projet**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Milestone 1** : Faisabilité de classification – Texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conseils\n",
    "\n",
    "**Livrable** : Notebook d’analyse de faisabilité de classification automatique des produits par leur description textuelle.\n",
    "\n",
    "**Charge** : 30 %\n",
    "\n",
    "**Problèmes et erreurs courants** :\n",
    "* ⚠ L’objectif est de vérifier la faisabilité de classifier automatiquement les produits, simplement via une représentation en 2D des produits et une vérification d’une séparation automatique selon leur catégorie réelle (classification non supervisée). Il n’est donc pas demandé de réaliser de classification supervisée de prédiction des catégories des produits.\n",
    "\n",
    "**Recommandations** :\n",
    "* Réaliser un prétraitement de texte : nettoyage (ponctuation, stopwords…), lemmatization…\n",
    "* Ce prétraitement doit être adapté au contexte et surtout à l’objectif. Nous cherchons à séparer les produits selon leur description textuelle. Les noms, voire certains verbes, permettent de décrire ces produits. Les adjectifs ou les adverbes sont beaucoup moins pertinents.\n",
    "* Réaliser un bag of words (countVectorizer, Tf-idf…) afin de créer des « features » pour chaque produit.\n",
    "Vous pourrez prendre la variable « description » et la variable « product_name » qui contient les principaux mots qui décrivent un produit.\n",
    "* Pour le bag of words, l’étudiant pourra tester plusieurs approches : par exemple fit et transform sur « description » ou sur « product_name » + « description », fit sur « product_name » et transform sur « product_name » + « description » (permet de ne garder que le vocabulaire des « product_name » moins verbeux, et de renforcer le comptage avec le contenu de « description ».\n",
    "* Réaliser une réduction de dimension via ACP. Une approche complémentaire via LDA afin de créer des features de dimension réduite peut être testée, elle n’est pas obligatoire.\n",
    "* Comme présenté dans le webinaire sur le traitement d’images (cf. onglet Ressources), réaliser un T-SNE afin de réduire à 2 composantes les features, et les afficher en coloriant selon la catégorie réelle (1er niveau de « product_category_tree » = 7 catégories, 150 produits par catégorie).\n",
    "* Le graphique montrera clairement que les produits sont relativement bien séparés selon les catégories réelles.\n",
    "* Afin de vérifier l’aspect visuel, réaliser un clustering k-means à partir des 2 composantes du T-SNE (7 clusters comme le nombre de catégories), afficher les 2 composantes du T-SNE en coloriant selon le numéro de cluster du k-means, et comparer la similarité de la catégorisation (catégorie réelle / cluster k-means) via l’adjusted Rand Score (ARI). La valeur, de l’ordre de 0.4 à 0.5, confirme le visuel et donc la faisabilité de classer automatiquement les produits.\n",
    "* En option, l’étudiant pourra analyser plus finement par sous-catégories.\n",
    "\n",
    "**Ressources** :\n",
    "* ARI : https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Milestone 2** : Faisabilité de classification – Text Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conseils\n",
    "\n",
    "**Livrable** : Notebook complémentaire au précédent, mettant en œuvre des techniques d’embedding.\n",
    "\n",
    "**Charge** : 15 %\n",
    "\n",
    "**Problèmes et erreurs courants** :\n",
    "* ⚠ Attention à ne pas passer trop de temps sur ce sujet ;).\n",
    "\n",
    "**Recommandations** :\n",
    "* L’objectif de cette étape est de permettre de découvrir des techniques NLP plus avancées.\n",
    "* Il existe, dans les ressources, un notebook donnant un exemple de mise en œuvre de ces techniques : Word2Vec (ou remplacé par Doc2Vec), BERT, USE (Universal Sentence Encoder).\n",
    "* Tu réaliseras la création de features à l’aide de chacune de ces trois techniques (technique de « feature extraction » orientée « sentence embedding »). Il n’est pas attendu une grande expertise, il s’agit surtout d’une introduction à ces techniques.\n",
    "* L’analyse graphique T-SNE et le calcul de l’ARI permettront de comparer les résultats avec les techniques plus simples de CountVectorizer ou Tf-idf.\n",
    "\n",
    "**Ressources** :\n",
    "* Notebook – Exemple de Sentence Embedding : cf. Ressources.\n",
    "* Word/sentence Embedding BERT – Hugging Face : Exemple de Word Embedding BERT via Hugging Face.\n",
    "* Word/sentence Embedding BERT – Hub pour  TensorFlow : exemple de Word Embedding BERT via le hub TensorFlow\n",
    "* Sentence Embedding USE :  Exemple de Sentence Embedding USE (Universal Sentence Encoder)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Milestone 3** : Faisabilité de classification automatique d’images via SIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conseils\n",
    "\n",
    "**Livrable** : Notebook d’analyse de faisabilité de classification automatique d’images via SIFT, ORB ou SURF\n",
    "\n",
    "**Niveau d’avancement** : 30 %\n",
    "\n",
    "**Problèmes et erreurs courants** :\n",
    "* ⚠ L’objectif est de vérifier la faisabilité de classifier automatiquement les images, simplement via une représentation en 2D des images et une vérification d’une séparation automatique selon leur catégorie réelle (classification non supervisée). Il n’est donc pas demandé de réaliser de classification supervisée de prédiction de catégories des images.\n",
    "\n",
    "**Recommandations** :\n",
    "* Le webinaire sur le traitement d’images (cf. onglet Ressources) indique dans le détail la réalisation d’extraction de features et l’affichage via T-SNE, afin de vérifier la séparation automatique de manière non supervisée des images par catégorie (classification non supervisée).\n",
    "* Réaliser dans un premier temps une analyse d’une image et différentes approches de transformation : niveaux de gris, equalization, filtrage bruit, contraste, floutage… (affichage image et histogramme associés).\n",
    "* Ensuite réaliser l’extraction des descripteurs (cf. webinaire).\n",
    "Puis générer les « features » des images via un bag of virtual words (création de clusters de descripteurs et comptage pour chaque image du nombre de descripteurs par cluster).\n",
    "* Réaliser une réduction de dimension (ACP).\n",
    "* Réaliser un T-SNE afin de réduire à 2 composantes les features, et les afficher en coloriant selon la catégorie réelle.\n",
    "* Il est assez difficile de séparer les images selon le label. Le résultat n’est donc pas très concluant avec SIFT.\n",
    "* Afin de vérifier l’aspect visuel, réaliser un clustering k-means à partir des 2 composantes du T-SNE (7 clusters comme le nombre de catégories réelles), afficher les 2 composantes du T-SNE en coloriant selon le numéro de cluster du k-means, et comparer la similarité de la catégorisation (catégorie réelle / cluster k-means) via l’Adjusted Rand Score (ARI). La valeur, de l’ordre de 0.05 à 0.1, confirme le visuel.\n",
    "\n",
    "**Ressources** :\n",
    "* ARI : https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Milestone 4** : Faisabilité de classification automatique d’images via CNN Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conseils\n",
    "\n",
    "**Livrable** : Notebook d’analyse de faisabilité de classification automatique d’images via CNN Transfer Learning.\n",
    "\n",
    "**Charge** : 25 %\n",
    "\n",
    "**Problèmes et erreurs courants** :\n",
    "* cf. milestone 3 (SIFT)\n",
    "\n",
    "**Recommandations** :\n",
    "* Récupérer un modèle préentraîné comme précisé dans la ressource « Transfer Learning in Keras with Computer Vision Models », en particulier le paragraphe « Pre-Trained Model as Feature Extractor Preprocessor ».\n",
    "* La suite est identique au milestone 3 (SIFT) :\n",
    "* ACP, T-SNE, k-means, affichage des 2 composantes T-SNE des images coloriées selon la catégorie réelle, puis selon le numéro de cluster, calcul ARI.\n",
    "* Le résultat tant visuel que calculé (0.4 à 0.6) est bien plus pertinent et montre, sans entraînement d’un modèle, la faisabilité de réaliser une classification automatique.\n",
    "\n",
    "**Ressources** :\n",
    "* Transfer Learning in Keras with Computer Vision Models : https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
